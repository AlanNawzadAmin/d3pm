{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_logits_from_logistic_pars(loc, log_scale, num_classes = 10):\n",
    "    loc = loc.unsqueeze(-1)\n",
    "    log_scale = log_scale.unsqueeze(-1)\n",
    "\n",
    "    inv_scale = (-log_scale + 2.0).exp()\n",
    "    \n",
    "    bin_width = 2.0 / (num_classes - 1)\n",
    "    bin_centers = torch.linspace(-1.0, 1.0, num_classes).to(loc.device)\n",
    "    bin_centers = bin_centers.reshape((*loc.shape, num_classes))\n",
    "    bin_centers = bin_centers - loc\n",
    "    log_cdf_min = -torch.log1p((-inv_scale * (bin_centers - 0.5 * bin_width)).exp())\n",
    "    log_cdf_plus = -torch.log1p((-inv_scale * (bin_centers + 0.5 * bin_width)).exp())\n",
    "    logits = log_minus_exp(log_cdf_plus, log_cdf_min)\n",
    "    return logits\n",
    "\n",
    "def log_minus_exp(a, b, epsilon=1.e-6):\n",
    "    return a + torch.log1p(-torch.exp(b - a) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loc = torch.randn(1, 1, 1, 1).clip(-1, 1)\n",
    "log_scale = torch.randn(1, 1, 1, 1)\n",
    "\n",
    "num_classes = 10\n",
    "logits = get_logits_from_logistic_pars(loc, log_scale, num_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[0,0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(1/(1 + exp(-x - eps) - 1/(1 + exp(-x + eps)))\n",
    "# plot \n",
    "inv_scale = 10\n",
    "f = lambda x : np.log(1/(1 + np.exp(- inv_scale * (x  + 0.1))) - 1/(1 + np.exp(- inv_scale* (x  - 0.1))))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.linspace(-1, 1, 100)\n",
    "y = f(x)\n",
    "plt.plot(x, y)\n",
    "plt.yticks(np.arange(-10, 10, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "beta = 0.1\n",
    "mat = torch.ones(num_classes, num_classes) * beta / num_classes\n",
    "# diagonal is 1 - (K - 1)/K * beta\n",
    "mat.diagonal().fill_(1 - (num_classes - 1) * beta / num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "\n",
    "blk = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 7, padding=3),\n",
    "    nn.GroupNorm(oc // 8, oc, affine = False, eps = 1e-4),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "\n",
    "class DummyX0Model(nn.Module):\n",
    "    \"\"\"\n",
    "    This should be unet-like, but let's don't think about the model too much :P\n",
    "    Basically, any universal R^n -> R^n model should work.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_channel: int, N) -> None:\n",
    "        super(DummyX0Model, self).__init__()\n",
    "        self.start =  blk(n_channel, 16)\n",
    "        self.pe = nn.Parameter(torch.randn(1, 16, 32, 32))\n",
    "        self.conv = nn.Sequential(\n",
    "            blk(16, 128),\n",
    "            blk(128, 256),\n",
    "            blk(256, 512),\n",
    "            blk(512, 256),\n",
    "            blk(256, 128),\n",
    "            blk(128, 64),\n",
    "            nn.Conv2d(64, 2 * n_channel, 3, padding=1),\n",
    "        )\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, x, t) -> torch.Tensor:\n",
    "        # Lets think about using t later. In the paper, they used Tr-like positional embeddings.\n",
    "        st = x.float() / self.N - 0.5\n",
    "        x = self.start(st) + self.pe\n",
    "        y = self.conv(x)\n",
    "        loc, log_scale = y.chunk(2, dim=1)\n",
    "\n",
    "        return torch.tanh(loc + st), log_scale\n",
    "\n",
    "blk = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "blku = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.ConvTranspose2d(oc, oc, 2, stride=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    \n",
    ")\n",
    "\n",
    "class DummyX0Model(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, n_channel: int, N : int = 16) -> None:\n",
    "        super(DummyX0Model, self).__init__()\n",
    "        self.down1 = blk(n_channel, 16)\n",
    "        self.down2 = blk(16, 32)\n",
    "        self.down3 = blk(32, 64)\n",
    "        self.down4 = blk(64, 512)\n",
    "        self.down5 = blk(512, 512)\n",
    "        self.up1 = blku(512, 512)\n",
    "        self.up2 = blku(512 + 512, 64)  # Corrected to account for concatenated feature maps\n",
    "        self.up3 = blku(64 + 64, 32)    # Corrected to account for concatenated feature maps\n",
    "        self.up4 = blku(32 + 32, 16)    # Corrected to account for concatenated feature maps\n",
    "        self.convlast = blk(32, 16)\n",
    "        self.final = nn.Conv2d(16, N * n_channel, 1, bias = False)\n",
    "\n",
    "        # initialize final with zero\n",
    "        #self.final.weight.data.zero_()\n",
    "        #self.final.bias.data.zero_()\n",
    "\n",
    "        self.tr1 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr2 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr3 = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n",
    "\n",
    "        self.temb_1 = nn.Linear(32, 16)\n",
    "        self.temb_2 = nn.Linear(32, 32)\n",
    "        self.temb_3 = nn.Linear(32, 64)\n",
    "        self.temb_4 = nn.Linear(32, 512)\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, x, t) -> torch.Tensor:\n",
    "        x = (2 * x.float() / self.N) - 1.0\n",
    "        t = t.float().reshape(-1, 1) / 500\n",
    "        t_as_sin = [torch.sin(t * 3.1415 * 2 ** i) for i in range(16)]\n",
    "        t_as_cos = [torch.cos(t * 3.1415 * 2 ** i) for i in range(16)]\n",
    "        # concat and send it to t_emb\n",
    "        t_emb_1 = self.temb_1(torch.cat(t_as_sin + t_as_cos, dim=1).to(x.device)).reshape(x.shape[0], -1, 1, 1)\n",
    "        t_emb_2 = self.temb_2(torch.cat(t_as_sin + t_as_cos, dim=1).to(x.device)).reshape(x.shape[0], -1, 1, 1)\n",
    "        t_emb_3 = self.temb_3(torch.cat(t_as_sin + t_as_cos, dim=1).to(x.device)).reshape(x.shape[0], -1, 1, 1)\n",
    "        t_emb_4 = self.temb_4(torch.cat(t_as_sin + t_as_cos, dim=1).to(x.device)).reshape(x.shape[0], -1, 1, 1)\n",
    "        \n",
    "        x1 = self.down1(x) + t_emb_1\n",
    "        x2 = self.down2(nn.functional.avg_pool2d(x1, 2)) + t_emb_2\n",
    "        x3 = self.down3(nn.functional.avg_pool2d(x2, 2)) + t_emb_3\n",
    "        x4 = self.down4(nn.functional.avg_pool2d(x3, 2)) + t_emb_4\n",
    "        x5 = self.down5(nn.functional.avg_pool2d(x4, 2))\n",
    "\n",
    "        x5 = self.tr1(x5.reshape(x5.shape[0], x5.shape[1], -1).transpose(1, 2)).transpose(1, 2).reshape(x5.shape)\n",
    "\n",
    "        y = self.up1(x5)\n",
    "\n",
    "        y = self.tr2(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2)).transpose(1, 2).reshape(y.shape)\n",
    "  \n",
    "        y = self.up2(torch.cat([x4, y], dim=1))\n",
    "\n",
    "        y = self.tr3(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2)).transpose(1, 2).reshape(y.shape)\n",
    "\n",
    "        y = self.up3(torch.cat([x3, y], dim=1))\n",
    "\n",
    "        y = self.up4(torch.cat([x2, y], dim=1))\n",
    "\n",
    "\n",
    "        y = self.convlast(torch.cat([x1, y], dim=1))\n",
    "        y = self.final(y)\n",
    "        # reshape to B, C, H, W, N\n",
    "        y = y.reshape(y.shape[0], -1, self.N, *x.shape[2:]).transpose(2, -1).contiguous()\n",
    "      \n",
    "        return y\n",
    "\n",
    "\n",
    "# check if it takes 2, 1, 28, 28 input\n",
    "\n",
    "model = DummyX0Model(1, N = 16)\n",
    "print(model(torch.randn(2, 1, 32, 32), torch.tensor([1, 2])).shape)\n",
    "\n",
    "\n",
    "\n",
    "def get_logits_from_logistic_pars(loc, log_scale, num_classes = 10):\n",
    "    loc = loc.unsqueeze(-1)\n",
    "    log_scale = log_scale.unsqueeze(-1)\n",
    "    inv_scale = (-log_scale + 2.0).exp()\n",
    "\n",
    "    bin_width = 2.0 / (num_classes - 1)\n",
    "    bin_centers = torch.linspace(-1.0, 1.0, num_classes).to(loc.device)\n",
    "    bin_centers = bin_centers.reshape([1] * (len(loc.shape) - 1) + [num_classes])\n",
    "    bin_centers = bin_centers - loc\n",
    "    log_cdf_min = -torch.log1p((-inv_scale * (bin_centers - 0.5 * bin_width)).exp())\n",
    "    log_cdf_plus = -torch.log1p((-inv_scale * (bin_centers + 0.5 * bin_width)).exp())\n",
    "    logits = log_minus_exp(log_cdf_plus, log_cdf_min)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def log_minus_exp(a, b, epsilon=1e-6):\n",
    "    return a + torch.log1p(-torch.exp(b - a) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "class D3PM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x0_model: nn.Module,\n",
    "        n_T: int,\n",
    "        num_classes: int = 10,\n",
    "        forward_type = 'uniform',\n",
    "        hybrid_loss_coeff = 0.001\n",
    "    ) -> None:\n",
    "        super(D3PM, self).__init__()\n",
    "        self.x0_model = x0_model\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.hybrid_loss_coeff = hybrid_loss_coeff\n",
    "        self.beta_t = [1 / (self.n_T - t + 1) for t in range(1, self.n_T + 1)]\n",
    "        self.eps = 1e-8\n",
    "        self.num_classses = num_classes\n",
    "        q_onestep_mats = []\n",
    "        q_mats = [] # these are cumulative\n",
    "\n",
    "        for beta in self.beta_t:\n",
    "\n",
    "            if forward_type == 'uniform':\n",
    "                mat = torch.ones(num_classes, num_classes) * beta / num_classes\n",
    "                mat.diagonal().fill_(1 - (num_classes - 1) * beta / num_classes)\n",
    "                q_onestep_mats.append(mat)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        q_one_step_mats = torch.stack(q_onestep_mats, dim=0)\n",
    "\n",
    "        q_one_step_transposed = q_one_step_mats.transpose(1, 2) # this will be used for q_posterior_logits\n",
    "\n",
    "        q_mat_t = q_onestep_mats[0]\n",
    "        q_mats = [q_mat_t]\n",
    "        for idx in range(1, self.n_T):\n",
    "            q_mat_t = q_mat_t @ q_onestep_mats[idx]\n",
    "            q_mats.append(q_mat_t)\n",
    "        q_mats = torch.stack(q_mats, dim=0)\n",
    "        self.logit_type = 'logit'\n",
    "\n",
    "        # register\n",
    "        self.register_buffer(\"q_one_step_transposed\", q_one_step_transposed)\n",
    "        self.register_buffer(\"q_mats\", q_mats)\n",
    "\n",
    "        assert self.q_mats.shape == (self.n_T, num_classes, num_classes), self.q_mats.shape\n",
    "    \n",
    "    def _at(self, a, t, x):\n",
    "        # t is 1-d, x is integer value of 0 to num_classes - 1\n",
    "        bs = t.shape[0]\n",
    "        t = t.reshape((bs, *[1] * (x.dim() - 1)))\n",
    "        #out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
    "        return a[t - 1, x, :]\n",
    "\n",
    "\n",
    "    def q_posterior_logits(self, x_0, x_t, t):\n",
    "        # if t == 1, this means we return the L_0 loss, so directly try to x_0 logits.\n",
    "        # otherwise, we return the L_{t-1} loss.\n",
    "        # Also, we never have t == 0.\n",
    "\n",
    "        # if x_0 is integer, we convert it to one-hot.\n",
    "        if x_0.dtype == torch.int64 or x_0.dtype == torch.int32:\n",
    "            x_0_logits = torch.log(torch.nn.functional.one_hot(x_0, self.num_classses) + self.eps)\n",
    "        else:\n",
    "            x_0_logits = x_0.clone()\n",
    "\n",
    "        assert x_0_logits.shape == x_t.shape + (self.num_classses,), print(f\"x_0_logits.shape: {x_0_logits.shape}, x_t.shape: {x_t.shape}\")\n",
    "\n",
    "        # Here, we caclulate equation (3) of the paper. Note that the x_0 Q_t x_t^T is a normalizing constant, so we don't deal with that.\n",
    "        # fact1 is \"guess of x_{t-1}\" from x_t\n",
    "        # fact2 is \"guess of x_{t-1}\" from x_0\n",
    "\n",
    "        fact1 = self._at(self.q_one_step_transposed, t, x_t)\n",
    "        #fact2 = self._at_onehot(self.q_mats, t-1, )\n",
    "        # x, a[t-1]\n",
    "\n",
    "\n",
    "        softmaxed = torch.softmax(x_0_logits, dim=-1) # bs, ..., num_classes\n",
    "        qmats2 = self.q_mats[t-2] # bs, num_classes, num_classes\n",
    "\n",
    "        fact2 = torch.einsum('b...c,bcd->b...d', softmaxed, qmats2)\n",
    "    \n",
    "        #print(f\"Fact1Fact2\", fact1.shape, fact2.shape)\n",
    "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
    "        #print(f\"out: {out.shape}\")\n",
    "        t_broadcast = t.reshape((t.shape[0], *[1] * (x_t.dim())))\n",
    "        #print(t_broadcast.shape)\n",
    "        bc = torch.where(t_broadcast == 1, x_0_logits, out)\n",
    "        #print(f\"bc: {bc.shape}\")\n",
    "        return bc\n",
    "\n",
    "    def vb(self, dist1, dist2):\n",
    "        out = (torch.softmax(dist1 + self.eps, dim = -1)*(torch.log_softmax(dist1 + self.eps, dim = -1) - torch.log_softmax(dist2 + self.eps, dim = -1)))\n",
    "        return out.sum(dim=-1).mean()\n",
    "\n",
    "        \n",
    "    def q_sample(self, x_0, t, noise):\n",
    "        # forward process, x_0 is the clean input.\n",
    "        \n",
    "        logits = torch.log(self._at(self.q_mats, t, x_0) + self.eps)\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "\n",
    "    def model_predict(self, x_0, t):\n",
    "        if self.logit_type == 'logit':\n",
    "            predicted_x0_logits = self.x0_model(x_0, t)\n",
    "        else:\n",
    "            loc, log_scale = self.x0_model(x_0, t)\n",
    "            predicted_x0_logits = get_logits_from_logistic_pars(loc, log_scale, self.num_classses)\n",
    "        return predicted_x0_logits\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Makes forward diffusion x_t from x_0, and tries to guess x_0 value from x_t using x0_model.\n",
    "        x is one-hot of dim (bs, ...), with int values of 0 to num_classes - 1\n",
    "        \"\"\"\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        x_t = self.q_sample(x, t, torch.rand((*x.shape, self.num_classses), device=x.device))\n",
    "        # x_t is same shape as x\n",
    "        assert x_t.shape == x.shape, print(f\"x_t.shape: {x_t.shape}, x.shape: {x.shape}\")\n",
    "        # we use hybrid loss.\n",
    "        \n",
    "        predicted_x0_logits = self.model_predict(x, t)\n",
    "\n",
    "\n",
    "        # based on this, we first do vb loss.\n",
    "        true_q_posterior_logits = self.q_posterior_logits(x, x_t, t)\n",
    "        #print(f\"predicted_x0_logits: {predicted_x0_logits.shape}, true_q_posterior_logits: {true_q_posterior_logits.shape}\")\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x_t, t)\n",
    "\n",
    "        vb_loss = self.vb(true_q_posterior_logits,pred_q_posterior_logits)\n",
    "\n",
    "\n",
    "\n",
    "        predicted_x0_logits = predicted_x0_logits.flatten(start_dim = 0, end_dim = -2)\n",
    "        x = x.flatten(start_dim = 0, end_dim = -1)\n",
    "        #print(f\"predicted_x0_logits: {predicted_x0_logits.shape}, x: {x.shape}\")\n",
    "\n",
    "\n",
    "        ce_loss = torch.nn.CrossEntropyLoss()(predicted_x0_logits, x)\n",
    "\n",
    "        return vb_loss + ce_loss*self.hybrid_loss_coeff, {\"vb_loss\": vb_loss.detach().item(), \"ce_loss\": ce_loss.detach().item()}\n",
    "\n",
    "    def p_sample(self, x, t, noise):\n",
    "        \n",
    "        predicted_x0_logits = self.model_predict(x, t)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x, t)\n",
    "\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "\n",
    "        not_first_step = (t != 1).float().reshape((x.shape[0], *[1] * (x.dim())))\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        sample = torch.argmax(pred_q_posterior_logits + gumbel_noise * not_first_step, dim=-1)\n",
    "        return sample\n",
    "\n",
    "    def sample(self, x = None):\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t]*x.shape[0], device=x.device)\n",
    "            x = self.p_sample(x, t, torch.rand((*x.shape, self.num_classses), device=x.device))\n",
    "     \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d3pm = D3PM(DummyX0Model(1, 20), 1000, num_classes = 20).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d3pm.sample(torch.randint(0, 2, (2, 1, 32, 32)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d3pm.train()\n",
    "# d3pm.forward(torch.randint(0, 2, (128, 1, 28, 28)).cuda())\n",
    "# dataset = MNIST(\n",
    "#         \"./data\",\n",
    "#         train=True,\n",
    "#         download=True,\n",
    "#         transform=transforms.ToTensor()\n",
    "#     )\n",
    "# dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=20)\n",
    "# d3pm(x = next(iter(dataloader))[0].cuda().long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16\n",
    "d3pm = D3PM(DummyX0Model(1, N), 1000, num_classes = N, hybrid_loss_coeff=0.0).cuda()\n",
    "print(f\"Total Param Count: {sum([p.numel() for p in d3pm.x0_model.parameters()])}\")\n",
    "dataset = MNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform= transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Pad(2),\n",
    "        ])\n",
    "    )\n",
    "dataloader = DataLoader([dataset[0]] * 50000, batch_size=32, shuffle=True, num_workers=32)\n",
    "#dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=32)\n",
    "\n",
    "optim = torch.optim.AdamW(d3pm.x0_model.parameters(), lr=4e-4, betas=(0.95, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3pm.train()\n",
    "\n",
    "n_epoch = 10\n",
    "device = 'cuda'\n",
    "from torchvision.utils import make_grid\n",
    "from matplotlib import pyplot as plt\n",
    "global_step = 0\n",
    "for i in range(n_epoch):\n",
    "    d3pm.train()\n",
    "    pbar = tqdm(dataloader)\n",
    "    loss_ema = None\n",
    "    for x, _ in pbar:\n",
    "        #print(x)\n",
    "        optim.zero_grad()\n",
    "        x = x.to(device)\n",
    "        # discritize x to 10 bins\n",
    "        x = (x * N).long().clamp(0, N - 1)\n",
    "        \n",
    "        loss, info = d3pm(x)\n",
    "        \n",
    "        # if loss.item() > 1000 or torch.isnan(loss):\n",
    "        #     print(f\"loss is too high, skipping, {loss.item()}\")\n",
    "        #     loss.backward()\n",
    "        #     optim.zero_grad()\n",
    "        #     continue\n",
    "        #print(loss.item())\n",
    "        loss.backward()\n",
    "        norm = torch.nn.utils.clip_grad_norm_(d3pm.x0_model.parameters(), 0.01)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            param_norm = sum([torch.norm(p) for p in d3pm.x0_model.parameters()])\n",
    "        if loss_ema is None:\n",
    "            loss_ema = loss.item()\n",
    "        else:\n",
    "            loss_ema = 0.99 * loss_ema + 0.01 * loss.item()\n",
    "        pbar.set_description(f\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\")\n",
    "        optim.step()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 300 == 1:\n",
    "            d3pm.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x = d3pm.sample(torch.randint(0, N, (4, 1, 32, 32)).cuda())\n",
    "                x_as_image = make_grid(x.float() / N, nrow=4)\n",
    "                plt.figure()\n",
    "                plt.imshow(x_as_image.permute(1, 2, 0).cpu().numpy())\n",
    "                plt.show()\n",
    "\n",
    "            d3pm.train()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first dataset\n",
    "x = next(iter(dataloader))[0][:1]\n",
    "x_as_image = make_grid(x.float(), nrow=1)\n",
    "plt.figure()\n",
    "plt.imshow(x_as_image.permute(1, 2, 0).cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check parameter distribution\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def plot_param_dist(model):\n",
    "    plot_dist = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            plot_dist[name] = param.detach().cpu().numpy().flatten()\n",
    "            # sample 1000\n",
    "            # replace nan with 1000\n",
    "            plot_dist[name] = np.where(np.isnan(plot_dist[name]), 10, plot_dist[name])\n",
    "            plot_dist[name] = np.random.choice(plot_dist[name], 1000)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    for idx, (name, dist) in enumerate(plot_dist.items()):\n",
    "    \n",
    "        plt.hist(dist, bins=100, density=True)\n",
    "        \n",
    "    # log y\n",
    "    plt.yscale('log')\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_param_dist(d3pm.x0_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d3pm.q_mats[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# THIS CHECKS IF Q SAMPLE REALLY SAMPLES from Q.\n",
    "\n",
    "x = torch.tensor([[0]])\n",
    "collects = []\n",
    "for idx in range(10000):\n",
    "    sample = d3pm.q_sample(x, torch.tensor([200], device = 'cuda:0'), torch.rand((*x.shape, d3pm.num_classses), device='cuda:0'))\n",
    "    collects.append(sample.item())\n",
    "\n",
    "# plot histogram\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(collects, columns=['sample'])\n",
    "df['sample'].hist(bins=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmats = torch.arange(0, 1000).reshape(10, 10, 10)\n",
    "image_as_pixels = torch.randint(0, 10, (1, 1, 1))\n",
    "print(image_as_pixels)\n",
    "qmats[image_as_pixels].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmats[1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu122py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
