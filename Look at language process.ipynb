{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f7e46-73d8-483f-8d8b-01d29f1031c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import faiss\n",
    "import scipy\n",
    "from scipy.sparse import coo_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ced1e-2a69-4f1a-99f4-a5517edb0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf10712-cd61-45ec-bbcf-a4f536fe6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings and get knn\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "embeds = model.embeddings.word_embeddings.weight\n",
    "embeds = embeds.detach().cpu().numpy()\n",
    "\n",
    "norms = np.linalg.norm(embeds, axis=1, keepdims=True)\n",
    "embeds_normalized = embeds / norms\n",
    "\n",
    "print(\"Constructing nearest neighbor matrix...\")\n",
    "\n",
    "k = 10\n",
    "index = faiss.IndexFlatIP(embeds.shape[1]) \n",
    "index.add(embeds_normalized)\n",
    "distances, indices = index.search(embeds_normalized, k+1)\n",
    "distances = distances[:, 1:]\n",
    "indices = indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf8910-5ef2-4c97-98f1-db5851342043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab = np.array(list(tokenizer.get_vocab().keys()))\n",
    "unused = np.array(['[unused' in key for key in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681931a-9ca3-4324-9247-8dc114671e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot knn\n",
    "plt.figure(figsize=[4, 4])\n",
    "_, bins, _ = plt.hist(distances[:, 0][~unused], bins=100, color='red', alpha=0.5, label='closest');\n",
    "_, bins, _ = plt.hist(distances[:, -1][~unused], bins=100, color='blue', alpha=0.5, label='furthest');\n",
    "plt.hist(distances[:, -1][unused], bins=bins, color='black', label='unused tokens');\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(\"neighbour similarity\")\n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=[6, 2])\n",
    "plt.plot(distances.min(-1), color='black')\n",
    "plt.xlabel(\"token number\")\n",
    "plt.ylabel(\"min neighbour sim\")\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7d81f-81b7-4a60-b8e3-411ee505f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = np.repeat(np.arange(embeds.shape[0]), k) \n",
    "col_indices = indices.flatten()\n",
    "dot_products = distances.flatten()\n",
    "assert (dot_products > 0).all()\n",
    "assert (row_indices != col_indices).all()\n",
    "row_indices = np.r_[row_indices, np.arange(len(embeds))]\n",
    "col_indices = np.r_[col_indices, np.arange(len(embeds))]\n",
    "rates = distances.sum(-1)\n",
    "dot_products = np.r_[dot_products, -rates] / rates.max()\n",
    "\n",
    "sparse_matrix = coo_matrix((dot_products, (row_indices, col_indices)), shape=(embeds.shape[0], embeds.shape[0]))\n",
    "sparse_matrix_csr = sparse_matrix.tocsr()\n",
    "\n",
    "print(\"Finished constructing nearest neighbor matrix...\")\n",
    "\n",
    "L = sparse_matrix_csr\n",
    "rate = - (L.diagonal().min()) / (1-gamma) \n",
    "K = L / rate + scipy.sparse.eye(L.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e48a67-1af7-4c69-b8e2-63c398ea9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.random.randn(len(embeds))\n",
    "%timeit K @ (K @ (K @ (K @ g)))\n",
    "\n",
    "K_power = K @ K @ K @ K\n",
    "%timeit K_power @ g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5744b76-7ccd-46b4-bbb0-47985c848527",
   "metadata": {},
   "source": [
    "#### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c7f59-2c07-4f14-bbf6-e1699495cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import data\n",
    "cfg = OmegaConf.load('configs/basic_language.yaml')\n",
    "train_dataloader, test_dataloader = data.get_dataloaders(cfg)\n",
    "\n",
    "datum = next(iter(train_dataloader))\n",
    "tokenizer.decode(datum['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b0067-9c1e-48a2-9530-63cdc04f7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.randint(len(embeds), size=(128, 1000))\n",
    "%timeit K[inds.ravel(), :].toarray().reshape(*inds.shape, K.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7bfa35-1553-43f9-bf44-e2d0e3601623",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.randint(len(embeds), size=(128, 1000))\n",
    "%timeit (K@K[:, inds.ravel()]).toarray().reshape(K.shape[0], *inds.shape)\n",
    "%timeit K@(K[:, inds.ravel()].toarray()).reshape(K.shape[0], *inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa64a7-b76b-4b22-a25d-e24be7981dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_powers = 20\n",
    "current_prod = scipy.sparse.eye(K.shape[0])\n",
    "K_powers = [current_prod]\n",
    "for _ in range(num_powers):\n",
    "    current_prod = current_prod @ K\n",
    "    K_powers.append(current_prod)\n",
    "for i in range(num_powers):\n",
    "    scipy_coo = K_powers[i].tocoo()\n",
    "    row = torch.from_numpy(scipy_coo.row.astype(np.int64))\n",
    "    col = torch.from_numpy(scipy_coo.col.astype(np.int64))\n",
    "    data = torch.from_numpy(scipy_coo.data)\n",
    "    indices = torch.stack([row, col], dim=0)\n",
    "    shape = scipy_coo.shape\n",
    "    torch_sparse_tensor = torch.sparse_coo_tensor(indices, data, size=shape)\n",
    "    K_powers[i] = torch_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05301aa-2574-4d3b-9467-6e3cb72406b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evodiff",
   "language": "python",
   "name": "evodiff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
