{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f7e46-73d8-483f-8d8b-01d29f1031c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cola\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from transformers import BertModel, BertTokenizer, BertForMaskedLM\n",
    "import faiss\n",
    "import scipy\n",
    "from scipy.sparse import coo_matrix, coo_array\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ced1e-2a69-4f1a-99f4-a5517edb0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf10712-cd61-45ec-bbcf-a4f536fe6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings and get knn\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "embeds = model.cls.predictions.decoder.weight#model.embeddings.word_embeddings.weight\n",
    "embeds = embeds.detach().cpu().numpy()\n",
    "\n",
    "norms = np.linalg.norm(embeds, axis=1, keepdims=True)\n",
    "embeds_normalized = embeds / norms#np.maximum(1, norms)\n",
    "\n",
    "# get vocab\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab = np.array(list(tokenizer.get_vocab().keys()))\n",
    "unused = np.array(['[unused' in key for key in vocab])\n",
    "print(\"Constructing nearest neighbor matrix...\")\n",
    "\n",
    "k = 10\n",
    "is_unused = np.array([t.startswith(\"[\") and t.endswith(\"]\") for t in vocab])\n",
    "is_suffix = np.array([t.startswith(\"##\") for t in vocab])\n",
    "is_number = np.array([all([x in np.arange(10).astype(str) for x in t]) for t in vocab])\n",
    "is_normal = ~np.any([is_unused, is_suffix, is_number], axis=0)\n",
    "indices = np.empty([len(embeds), k])\n",
    "distances = np.empty([len(embeds), k])\n",
    "range_ = np.arange(len(embeds))\n",
    "for mask in tqdm([is_unused, is_suffix, is_number, is_normal]):\n",
    "    index = faiss.IndexFlatIP(embeds.shape[1]) \n",
    "    index.add(embeds_normalized[mask])\n",
    "    distances_temp, indices_temp = index.search(embeds_normalized[mask], k+1)\n",
    "    distances[mask] = distances_temp[:, 1:]\n",
    "    indices[mask] = range_[mask][indices_temp[:, 1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681931a-9ca3-4324-9247-8dc114671e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = 1 # max_ = 2.1\n",
    "# plot knn\n",
    "plt.figure(figsize=[4, 4])\n",
    "_, bins, _ = plt.hist(distances[:, 0][~unused], bins=100, color='red', alpha=0.5, label='closest');\n",
    "_, bins, _ = plt.hist(distances[:, -1][~unused], bins=100, color='blue', alpha=0.5, label='furthest');\n",
    "plt.hist(distances[:, -1][unused], bins=bins, color='black', label='unused tokens');\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(\"neighbour similarity\")\n",
    "plt.xlim(0, max_**2)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=[6, 2])\n",
    "plt.plot(distances.min(-1), color='black')\n",
    "plt.xlabel(\"token number\")\n",
    "plt.ylabel(\"min neighbour sim\")\n",
    "plt.ylim(0, max_**2)\n",
    "\n",
    "plt.figure(figsize=[6, 2])\n",
    "plt.plot(norms, color='black')\n",
    "plt.xlabel(\"token number\")\n",
    "plt.ylabel(\"min neighbour sim\")\n",
    "# plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffed265-514d-4c87-8844-afc4b4f93097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "inds = np.random.randint(len(embeds), size=5)\n",
    "for ind in inds:\n",
    "    print(tokenizer.decode([ind]), \":\", ' '.join(vocab[indices[ind].astype(int)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7d81f-81b7-4a60-b8e3-411ee505f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = np.repeat(np.arange(embeds.shape[0]), k) \n",
    "col_indices = indices.flatten()\n",
    "dot_products = distances.flatten()\n",
    "assert (dot_products > 0).all()\n",
    "assert (row_indices != col_indices).all()\n",
    "row_indices = np.r_[row_indices, np.arange(len(embeds))]\n",
    "col_indices = np.r_[col_indices, np.arange(len(embeds))]\n",
    "rates = distances.sum(-1)\n",
    "dot_products = np.r_[dot_products, -rates] / rates.max()\n",
    "\n",
    "class all_ones(cola.ops.operator_base.LinearOperator):\n",
    "    def _matmat(self, v):\n",
    "        return v.sum(0, keepdim=True)\n",
    "    \n",
    "dtype = torch.float32\n",
    "device = 'cpu'\n",
    "N = len(embeds)\n",
    "# weight = torch.tensor(1/20000, dtype=dtype, device=device)\n",
    "# L = cola.ops.Sparse(torch.tensor(dot_products).to(dtype).to(device),\n",
    "#                     torch.tensor(row_indices).to(dtype).to(device),\n",
    "#                     torch.tensor(col_indices).to(dtype).to(device),\n",
    "#                     shape=(N, N)) \n",
    "# L = cola.ops.Dense(L.to_dense())\n",
    "# ones = all_ones(dtype, (N, N))\n",
    "# ones.device = L.device\n",
    "# L = L #+ weight * (ones - N * cola.ops.I_like(L))\n",
    "# rate = (torch.tensor(rates / rates.max(), dtype=dtype, device=device) + (N-1) * weight).max() / (1-gamma)\n",
    "# K = L / rate + cola.ops.I_like(L)\n",
    "\n",
    "sparse_matrix = coo_array((dot_products, (row_indices, col_indices)), shape=(embeds.shape[0], embeds.shape[0]))\n",
    "sparse_matrix_csr =sparse_matrix.tocsr()\n",
    "L = sparse_matrix_csr\n",
    "rate = - (L.diagonal().min()) / (1-gamma) \n",
    "K = L / rate + scipy.sparse.eye(L.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d018f8-3cf5-4cb0-adec-d7f693d29dc1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "l, u = cola.linalg.eig(K, 1)\n",
    "l2, u2 = cola.linalg.eig(K - cola.ops.Dense(u)@cola.ops.Dense(u.T), 1)\n",
    "print(l, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d934dc-3ade-4e17-b75e-58ad486177b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = torch.tensor(np.random.randint(len(embeds), size=[16, 1024]), dtype=torch.int32, device=device)\n",
    "S = torch.tensor(np.random.randint(1000, size=x_0.shape), dtype=torch.int32, device=device)\n",
    "\n",
    "def sample_probs(probs):\n",
    "    n_rows, n_cols = probs.shape\n",
    "    u = np.random.random(n_rows)\n",
    "    csc = probs.tocsc()\n",
    "    cumsum = csc.cumsum(axis=1)\n",
    "    samples = (u <= cumsum.toarray()).argmax(axis=1)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def f(S, x_0, period=1):\n",
    "    shape = x_0.shape\n",
    "    x_0 = x_0.flatten().numpy()\n",
    "    x_curr = x_0\n",
    "    x_t = np.ones_like(x_0)\n",
    "    curr_S = S.flatten().numpy()\n",
    "    pbar = tqdm(total=curr_S.sum(), unit=\"iteration\",\n",
    "                position=0, leave=True)\n",
    "    while any(curr_S > 0):\n",
    "        active = curr_S >= 0\n",
    "        x_t[curr_S == 0] = x_curr[(curr_S == 0)[active]]\n",
    "        if len(x_curr) == 1:\n",
    "            if not all((curr_S > 0)[active]):\n",
    "                break\n",
    "        else:\n",
    "            x_curr = x_curr[(curr_S > 0)[active]]\n",
    "        probs = K[x_curr]\n",
    "        # x_curr = sample_probs(probs)\n",
    "        curr_S = curr_S - 1\n",
    "        pbar.update(int(np.array((curr_S >= 0).sum())))\n",
    "    if len(x_curr) > 0:\n",
    "        x_t[curr_S == 0] = x_curr\n",
    "    return x_t.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1244bd8-7d22-4a27-ac26-1c389d1ffe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = f(S, x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcc84e-2db8-4ec2-9bae-757ffd159950",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f8c87-160a-4efe-b193-1609deb230e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = L.to_dense()\n",
    "print(A.dtype, A.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e725650-2fb8-4155-bc94-cff083f30ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.randn([len(embeds), 10], device=device)\n",
    "L.to_dense() @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e48a67-1af7-4c69-b8e2-63c398ea9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.randn([len(embeds), 10], device=device)\n",
    "%timeit L @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac740f-1c6d-44d6-acaf-a9a09a0a5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(L.toarray()[2000:2100, 2000:2100], vmin=-1, vmax=1, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814cb646-da01-48b5-9766-0a27fc597129",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.linalg.eigs(K, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fed18-454e-44ca-9d0c-482d03103767",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.randint(len(embeds), size=(32, 1024))\n",
    "%timeit K[inds.ravel(), :].toarray().reshape(*inds.shape, K.shape[1])\n",
    "%timeit K.T[inds.ravel(), :].toarray().reshape(*inds.shape, K.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5744b76-7ccd-46b4-bbb0-47985c848527",
   "metadata": {},
   "source": [
    "#### look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c7f59-2c07-4f14-bbf6-e1699495cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import data\n",
    "cfg = OmegaConf.load('configs/basic_language.yaml')\n",
    "train_dataloader, test_dataloader = data.get_dataloaders(cfg)\n",
    "\n",
    "datum = next(iter(train_dataloader))\n",
    "[tokenizer.decode(t) for t in datum['input_ids'][0].reshape(-1, 128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b0067-9c1e-48a2-9530-63cdc04f7dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7bfa35-1553-43f9-bf44-e2d0e3601623",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.randint(len(embeds), size=(128, 1000))\n",
    "%timeit (K@K[:, inds.ravel()]).toarray().reshape(K.shape[0], *inds.shape)\n",
    "%timeit K@(K[:, inds.ravel()].toarray()).reshape(K.shape[0], *inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa64a7-b76b-4b22-a25d-e24be7981dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_powers = 20\n",
    "current_prod = scipy.sparse.eye(K.shape[0])\n",
    "K_powers = [current_prod]\n",
    "for _ in range(num_powers):\n",
    "    current_prod = current_prod @ K\n",
    "    K_powers.append(current_prod)\n",
    "for i in range(num_powers):\n",
    "    scipy_coo = K_powers[i].tocoo()\n",
    "    row = torch.from_numpy(scipy_coo.row.astype(np.int64))\n",
    "    col = torch.from_numpy(scipy_coo.col.astype(np.int64))\n",
    "    data = torch.from_numpy(scipy_coo.data)\n",
    "    indices = torch.stack([row, col], dim=0)\n",
    "    shape = scipy_coo.shape\n",
    "    torch_sparse_tensor = torch.sparse_coo_tensor(indices, data, size=shape)\n",
    "    K_powers[i] = torch_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05301aa-2574-4d3b-9467-6e3cb72406b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evodiff2",
   "language": "python",
   "name": "evodiff2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
