{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5ef31-444c-4091-88a1-f5b59d6e492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from d3pm_sc.ct_sched_cond import ScheduleCondition\n",
    "from d3pm_sc.masking_diffusion import MaskingDiffusion\n",
    "from d3pm_sc.d3pm_classic import D3PMClassic\n",
    "from d3pm_sc.unet import KingmaUNet, UNet, SimpleUNet\n",
    "from d3pm_sc.dit import DiT_Llama\n",
    "from d3pm_sc import utils\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"6a47f093d2a55e4f4e85b33767423f2db66355b8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e6afe-cdfd-420c-b9b7-a69c45656461",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256  # number of classes for discretized state per pixel\n",
    "n_channel = 3\n",
    "gamma = 0\n",
    "hybrid_loss_coeff = 0.01\n",
    "logistic_pars = False\n",
    "fix_x_t_bias = False\n",
    "lr = 2e-4\n",
    "grad_clip_val = 1\n",
    "\n",
    "s_dim = 4\n",
    "conditional = False\n",
    "forward_kwargs = {\"type\":\"gaussian\",\n",
    "                  \"normalized\": True,\n",
    "                  \"bandwidth\":1 / 7}\n",
    "\n",
    "batch_size = 16\n",
    "n_epoch = 14 * torch.cuda.device_count()\n",
    "\n",
    "nn_params = {\"n_channel\": n_channel, \n",
    "             \"N\": N,\n",
    "             \"n_T\": 500,\n",
    "             \"schedule_conditioning\": True,\n",
    "             \"s_dim\":4,\n",
    "             \"num_classes\":10 if conditional else 1,\n",
    "             \"inc_attn\": False,\n",
    "             \"time_embed_dim\": 128,\n",
    "             # \"n_transformers\": 12,\n",
    "             # \"n_heads\": 12,\n",
    "             # \"ch\": 256,\n",
    "            }\n",
    "x0_model_class = KingmaUNet\n",
    "\n",
    "# x0_model_class = DiT_Llama\n",
    "# nn_params['dim'] = 1024\n",
    "\n",
    "##### Pick model\n",
    "# Schedule conditioning\n",
    "model = ScheduleCondition(x0_model_class, nn_params, num_classes=N, hybrid_loss_coeff=hybrid_loss_coeff, gamma=gamma,\n",
    "                          forward_kwargs=forward_kwargs, logistic_pars=logistic_pars, fix_x_t_bias=fix_x_t_bias, lr=lr, grad_clip_val=grad_clip_val)\n",
    "\n",
    "# # # Masking\n",
    "# nn_params[\"N\"] += 1\n",
    "# nn_params[\"schedule_conditioning\"] = False\n",
    "# model = MaskingDiffusion(x0_model_class, nn_params, num_classes=N, hybrid_loss_coeff=0.01).cuda()\n",
    "\n",
    "\n",
    "##### Load data\n",
    "dataset = CIFAR10(\n",
    "    \"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "def collate_fn(batch):\n",
    "    x, cond = zip(*batch)\n",
    "    x = torch.stack(x)\n",
    "    cond = torch.tensor(cond)\n",
    "    cond = (cond * conditional)\n",
    "    x = (x * (N - 1)).round().long().clamp(0, N - 1)\n",
    "    return x, cond\n",
    "train_size = int(len(dataset) * 0.9)\n",
    "dataset, test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=15, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=15, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdcb556-feb8-4a80-be82-61a98f5c691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = torch.arange(1000 + 1, dtype=torch.float64) / 1000\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=[9, 3])\n",
    "ax[0].semilogy(model.beta(steps), label=\"Hazard\", color='black')\n",
    "ax[0].legend()\n",
    "\n",
    "alpha_bar = torch.exp(model.log_alpha(steps))\n",
    "ax[1].plot(alpha_bar, label=\"p(unmut)\", color='black')\n",
    "ax[1].legend()\n",
    "\n",
    "L = utils.get_inf_gens(forward_kwargs, N)\n",
    "ax[2].imshow(L, vmin=-0.1, vmax=0.1, cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be842a7f-aee0-4e96-b885-f54daf0e2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb.init()\n",
    "wandb_logger = WandbLogger(project=\"debugging\")\n",
    "lightning_model = model\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# from pytorch_lightning.profilers import PyTorchProfiler\n",
    "# profiler = PyTorchProfiler(\n",
    "#     on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "#     schedule=torch.profiler.schedule(wait=1, warmup=1, active=10, repeat=2)\n",
    "# )\n",
    "trainer = Trainer(max_epochs=n_epoch, accelerator='auto',\n",
    "                  devices=torch.cuda.device_count(), logger=wandb_logger)#, profiler=profiler)\n",
    "trainer.fit(lightning_model, dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbadd67-27e6-4473-be73-3da103536320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fcee7-543d-4daf-a0a7-d6825b855aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.array(p.shape) for p in model.x0_model.down_blocks[0][0].parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b8b92-fa68-4c56-bd0d-2e287d22aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([np.prod(p) for p in a]))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a22b37-a0c4-45d0-b7e7-a3d879d615d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "31470288 - (17884416 + 11563008) * (1-48/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbad52-dabf-4ef7-bb00-dbda3466682a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evodiff",
   "language": "python",
   "name": "evodiff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
